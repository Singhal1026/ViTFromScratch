{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## 1. Import Required Liberaries","metadata":{}},{"cell_type":"code","source":"# import liberaries\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport random","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:47:54.039609Z","iopub.execute_input":"2026-02-04T04:47:54.039906Z","iopub.status.idle":"2026-02-04T04:48:03.002971Z","shell.execute_reply.started":"2026-02-04T04:47:54.039873Z","shell.execute_reply":"2026-02-04T04:48:03.002254Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"torch.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.004527Z","iopub.execute_input":"2026-02-04T04:48:03.004904Z","iopub.status.idle":"2026-02-04T04:48:03.010065Z","shell.execute_reply.started":"2026-02-04T04:48:03.004880Z","shell.execute_reply":"2026-02-04T04:48:03.009317Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'2.8.0+cu126'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"torchvision.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.011036Z","iopub.execute_input":"2026-02-04T04:48:03.011332Z","iopub.status.idle":"2026-02-04T04:48:03.056385Z","shell.execute_reply.started":"2026-02-04T04:48:03.011306Z","shell.execute_reply":"2026-02-04T04:48:03.055759Z"}},"outputs":[{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"'0.23.0+cu126'"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## 2. SetUp Device-Agnostic Code","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.057465Z","iopub.execute_input":"2026-02-04T04:48:03.057835Z","iopub.status.idle":"2026-02-04T04:48:03.106765Z","shell.execute_reply.started":"2026-02-04T04:48:03.057792Z","shell.execute_reply":"2026-02-04T04:48:03.106087Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"'cuda'"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"!nvidia-smi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.107670Z","iopub.execute_input":"2026-02-04T04:48:03.108039Z","iopub.status.idle":"2026-02-04T04:48:03.286147Z","shell.execute_reply.started":"2026-02-04T04:48:03.108006Z","shell.execute_reply":"2026-02-04T04:48:03.285221Z"}},"outputs":[{"name":"stdout","text":"Wed Feb  4 04:48:03 2026       \n+-----------------------------------------------------------------------------------------+\n| NVIDIA-SMI 580.105.08             Driver Version: 580.105.08     CUDA Version: 13.0     |\n+-----------------------------------------+------------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n|                                         |                        |               MIG M. |\n|=========================================+========================+======================|\n|   0  Tesla P100-PCIE-16GB           Off |   00000000:00:04.0 Off |                    0 |\n| N/A   38C    P0             27W /  250W |       3MiB /  16384MiB |      0%      Default |\n|                                         |                        |                  N/A |\n+-----------------------------------------+------------------------+----------------------+\n\n+-----------------------------------------------------------------------------------------+\n| Processes:                                                                              |\n|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n|        ID   ID                                                               Usage      |\n|=========================================================================================|\n|  No running processes found                                                             |\n+-----------------------------------------------------------------------------------------+\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"## 3. Set the Seed","metadata":{}},{"cell_type":"code","source":"torch.manual_seed(42)\ntorch.cuda.manual_seed(42)\nrandom.seed(42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.287408Z","iopub.execute_input":"2026-02-04T04:48:03.287726Z","iopub.status.idle":"2026-02-04T04:48:03.297359Z","shell.execute_reply.started":"2026-02-04T04:48:03.287670Z","shell.execute_reply":"2026-02-04T04:48:03.296748Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 4. Setting the HyperParameters","metadata":{}},{"cell_type":"code","source":"DATA_PATH = './data'\nBATCH_SIZE = 32\nEPOCHS = 30\nLEARNING_RATE = 3e-4\nPATCH_SIZE = 4\nNUM_CLASSES = 10\nIMAGE_SIZE = 96\nCHANNELS = 3\nEMBED_DIM = 256\nNUM_HEADS = 8\nDEPTH = 6\nMLP_DIM = 1024\nDROP_RATE = 0.1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.299419Z","iopub.execute_input":"2026-02-04T04:48:03.299683Z","iopub.status.idle":"2026-02-04T04:48:03.303749Z","shell.execute_reply.started":"2026-02-04T04:48:03.299664Z","shell.execute_reply":"2026-02-04T04:48:03.303061Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 5. Define Image Transformations","metadata":{}},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.Resize(96),                 #\n    transforms.RandomCrop(96, padding=8),\n    transforms.RandomHorizontalFlip(),\n    transforms.ColorJitter(\n        brightness=0.1,\n        contrast=0.1,\n        saturation=0.1,\n        hue=0.05\n    ),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=(0.5, 0.5, 0.5),\n        std=(0.5, 0.5, 0.5)\n    )\n])\n\ntest_transform = transforms.Compose([\n    transforms.Resize(96),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=(0.5, 0.5, 0.5),\n        std=(0.5, 0.5, 0.5)\n    )\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.304705Z","iopub.execute_input":"2026-02-04T04:48:03.304965Z","iopub.status.idle":"2026-02-04T04:48:03.317192Z","shell.execute_reply.started":"2026-02-04T04:48:03.304937Z","shell.execute_reply":"2026-02-04T04:48:03.316519Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## 6. Getting the Dataset","metadata":{}},{"cell_type":"code","source":"train_data = datasets.STL10(\n    root=DATA_PATH,\n    split=\"train\",\n    download=True,\n    transform=train_transform\n)\n\ntest_data = datasets.STL10(\n    root=DATA_PATH,\n    split=\"test\",\n    download=True,\n    transform=test_transform\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:03.318060Z","iopub.execute_input":"2026-02-04T04:48:03.318251Z","iopub.status.idle":"2026-02-04T04:48:59.920877Z","shell.execute_reply.started":"2026-02-04T04:48:03.318223Z","shell.execute_reply":"2026-02-04T04:48:59.920252Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 2.64G/2.64G [00:18<00:00, 146MB/s] \n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:48:59.930846Z","iopub.execute_input":"2026-02-04T04:48:59.931029Z","iopub.status.idle":"2026-02-04T04:48:59.941285Z","shell.execute_reply.started":"2026-02-04T04:48:59.931011Z","shell.execute_reply":"2026-02-04T04:48:59.940649Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Dataset STL10\n    Number of datapoints: 5000\n    Root location: ./data\n    Split: train\n    StandardTransform\nTransform: Compose(\n               Resize(size=96, interpolation=bilinear, max_size=None, antialias=True)\n               RandomCrop(size=(96, 96), padding=8)\n               RandomHorizontalFlip(p=0.5)\n               ColorJitter(brightness=(0.9, 1.1), contrast=(0.9, 1.1), saturation=(0.9, 1.1), hue=(-0.05, 0.05))\n               ToTensor()\n               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n           )"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"test_data","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.625504Z","iopub.execute_input":"2026-02-04T04:49:10.625840Z","iopub.status.idle":"2026-02-04T04:49:10.630777Z","shell.execute_reply.started":"2026-02-04T04:49:10.625798Z","shell.execute_reply":"2026-02-04T04:49:10.630140Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"Dataset STL10\n    Number of datapoints: 8000\n    Root location: ./data\n    Split: test\n    StandardTransform\nTransform: Compose(\n               Resize(size=96, interpolation=bilinear, max_size=None, antialias=True)\n               ToTensor()\n               Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n           )"},"metadata":{}}],"execution_count":12},{"cell_type":"markdown","source":"## 7. Converting Datasets into DataLoader","metadata":{}},{"cell_type":"code","source":"train_loader = DataLoader(\n    dataset=train_data, \n    batch_size=BATCH_SIZE, \n    shuffle=True\n)\n\ntest_loader = DataLoader(\n    dataset=test_data,\n    batch_size=BATCH_SIZE,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.632051Z","iopub.execute_input":"2026-02-04T04:49:10.632280Z","iopub.status.idle":"2026-02-04T04:49:10.645816Z","shell.execute_reply.started":"2026-02-04T04:49:10.632257Z","shell.execute_reply":"2026-02-04T04:49:10.645195Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"print(\"train_loader: \", train_loader, \"\\ntest_loader: \", test_loader)\nprint(\"Length of train_loader: \", len(train_loader))\nprint(\"Length of test_loader: \", len(test_loader))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.646582Z","iopub.execute_input":"2026-02-04T04:49:10.646933Z","iopub.status.idle":"2026-02-04T04:49:10.656929Z","shell.execute_reply.started":"2026-02-04T04:49:10.646898Z","shell.execute_reply":"2026-02-04T04:49:10.656212Z"}},"outputs":[{"name":"stdout","text":"train_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7b108f26cce0> \ntest_loader:  <torch.utils.data.dataloader.DataLoader object at 0x7b108eeb77d0>\nLength of train_loader:  157\nLength of test_loader:  250\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 8. Building ViT Model\n","metadata":{}},{"cell_type":"code","source":"class PatchEmbedding(nn.Module):\n    def __init__(self, img_size, patch_size, in_channels, embed_dim):\n        super().__init__()\n        self.proj = nn.Conv2d(\n            in_channels=in_channels,\n            out_channels=embed_dim,\n            kernel_size=patch_size,\n            stride=patch_size\n        )\n\n        num_patches = (img_size // patch_size) ** 2\n        self.cls_token = nn.Parameter(torch.randn(1,1,embed_dim))\n        self.pos_embed = nn.Parameter(torch.randn(1,1+num_patches,embed_dim))\n    \n    def forward(self, x: torch.Tensor):\n        B = x.shape[0]      # (B, 3, H, W)\n        x = self.proj(x)    # (B, embed_size, H/P, W/P), P-> patch_size\n        # But for transformer we need input with shape (B, num_patches, embed_dim)\n        x = x.flatten(2).transpose(1, 2)  # (B, num_patches, embed_dim)\n        cls_token = self.cls_token.expand(B, -1, -1)\n        x = torch.cat((cls_token, x), dim=1)\n        x = x + self.pos_embed\n        return x\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.657819Z","iopub.execute_input":"2026-02-04T04:49:10.658161Z","iopub.status.idle":"2026-02-04T04:49:10.667583Z","shell.execute_reply.started":"2026-02-04T04:49:10.658130Z","shell.execute_reply":"2026-02-04T04:49:10.666887Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"class MLP(nn.Module):\n    def __init__(self, in_features, hidden_features, drop_rate):\n        super().__init__()\n        self.fc1 = nn.Linear(\n            in_features=in_features,\n            out_features=hidden_features\n        )\n        self.fc2 = nn.Linear(\n            in_features=hidden_features,\n            out_features=in_features\n        )\n        self.dropout = nn.Dropout(drop_rate)\n\n    def forward(self, x):\n        x = self.fc1(x)\n        x = F.gelu(x)\n        x = self.dropout(x)\n\n        x = self.fc2(x)\n        x = self.dropout(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.669122Z","iopub.execute_input":"2026-02-04T04:49:10.669345Z","iopub.status.idle":"2026-02-04T04:49:10.680127Z","shell.execute_reply.started":"2026-02-04T04:49:10.669326Z","shell.execute_reply":"2026-02-04T04:49:10.679440Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"class MultiHeadAttention(nn.Module):\n    def __init__(self, dim: int, num_heads: int, dropout: float = 0.0, qkv_bias: bool = False):\n        super().__init__()\n\n        assert dim % num_heads == 0, \"dim must be divisible by num_heads\"\n\n        self.dim = dim\n        self.num_heads = num_heads\n        self.head_dim = dim // num_heads\n        self.scale = self.head_dim ** -0.5\n\n        self.W_query = nn.Linear(dim, dim, bias=qkv_bias)\n        self.W_key   = nn.Linear(dim, dim, bias=qkv_bias)\n        self.W_value = nn.Linear(dim, dim, bias=qkv_bias)\n\n        self.W_out = nn.Linear(dim, dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        # x: (batch_size, num_patches, dim)\n        B, N, D = x.shape\n\n        q = self.W_query(x)\n        k = self.W_key(x)\n        v = self.W_value(x)\n\n        # (B, N, dim) -> (B, num_heads, N, head_dim)\n        q = q.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n        k = k.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n        v = v.view(B, N, self.num_heads, self.head_dim).transpose(1, 2)\n\n        attn = (q @ k.transpose(-2, -1)) * self.scale\n        attn = attn.softmax(dim=-1)\n        attn = self.dropout(attn)\n\n        out = attn @ v\n        out = out.transpose(1, 2).contiguous().view(B, N, D)\n\n        out = self.W_out(out)\n        return out\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.680967Z","iopub.execute_input":"2026-02-04T04:49:10.681283Z","iopub.status.idle":"2026-02-04T04:49:10.693675Z","shell.execute_reply.started":"2026-02-04T04:49:10.681253Z","shell.execute_reply":"2026-02-04T04:49:10.692976Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class TransformerEncoderLayer(nn.Module):\n    def __init__(self, embed_dim, num_heads, mlp_dim, drop_rate):\n        super().__init__()\n        self.norm1 = nn.LayerNorm(embed_dim)\n        self.attn = MultiHeadAttention(embed_dim, num_heads, dropout=drop_rate)\n        self.norm2 = nn.LayerNorm(embed_dim)\n        self.mlp = MLP(embed_dim, mlp_dim, drop_rate)\n    \n    def forward(self, x):\n        shortcut = x\n        x = self.norm1(x)\n        x = self.attn(x)\n        x += shortcut\n\n        shortcut = x\n        x = self.norm2(x)\n        x = self.mlp(x)\n        x += shortcut\n\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.694550Z","iopub.execute_input":"2026-02-04T04:49:10.694886Z","iopub.status.idle":"2026-02-04T04:49:10.706414Z","shell.execute_reply.started":"2026-02-04T04:49:10.694864Z","shell.execute_reply":"2026-02-04T04:49:10.705771Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"class VisionTransformer(nn.Module):\n    def __init__(self, img_size, patch_size, in_channels, num_classes, embed_dim, depth, num_heads, mlp_dim, drop_rate):\n        super().__init__()\n        \n        self.patch_embed = PatchEmbedding(img_size, patch_size, in_channels, embed_dim)\n        self.encoder = nn.Sequential(*[\n            TransformerEncoderLayer(embed_dim, num_heads, mlp_dim, drop_rate) for _ in range(depth)\n        ])\n        self.norm = nn.LayerNorm(embed_dim)\n        self.head = nn.Linear(embed_dim, num_classes)\n\n    def forward(self, x):\n        x = self.patch_embed(x)\n        x = self.encoder(x)\n        x = self.norm(x)\n        cls_token = x[:, 0, :]\n        return self.head(cls_token)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.707250Z","iopub.execute_input":"2026-02-04T04:49:10.707473Z","iopub.status.idle":"2026-02-04T04:49:10.718215Z","shell.execute_reply.started":"2026-02-04T04:49:10.707444Z","shell.execute_reply":"2026-02-04T04:49:10.717623Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"# model instantiation\nmodel = VisionTransformer(\n    img_size = IMAGE_SIZE,\n    patch_size = PATCH_SIZE,\n    in_channels = CHANNELS,\n    num_classes = NUM_CLASSES,\n    embed_dim = EMBED_DIM,\n    depth = DEPTH,\n    num_heads = NUM_HEADS,\n    mlp_dim = MLP_DIM,\n    drop_rate = DROP_RATE\n).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.744819Z","iopub.execute_input":"2026-02-04T04:49:10.745192Z","iopub.status.idle":"2026-02-04T04:49:10.951744Z","shell.execute_reply.started":"2026-02-04T04:49:10.745159Z","shell.execute_reply":"2026-02-04T04:49:10.951146Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"model","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.952966Z","iopub.execute_input":"2026-02-04T04:49:10.953209Z","iopub.status.idle":"2026-02-04T04:49:10.958458Z","shell.execute_reply.started":"2026-02-04T04:49:10.953187Z","shell.execute_reply":"2026-02-04T04:49:10.957844Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"VisionTransformer(\n  (patch_embed): PatchEmbedding(\n    (proj): Conv2d(3, 256, kernel_size=(4, 4), stride=(4, 4))\n  )\n  (encoder): Sequential(\n    (0): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (1): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (2): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (3): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (4): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n    (5): TransformerEncoderLayer(\n      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (attn): MultiHeadAttention(\n        (W_query): Linear(in_features=256, out_features=256, bias=False)\n        (W_key): Linear(in_features=256, out_features=256, bias=False)\n        (W_value): Linear(in_features=256, out_features=256, bias=False)\n        (W_out): Linear(in_features=256, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n      (mlp): MLP(\n        (fc1): Linear(in_features=256, out_features=1024, bias=True)\n        (fc2): Linear(in_features=1024, out_features=256, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n    )\n  )\n  (norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n  (head): Linear(in_features=256, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":21},{"cell_type":"markdown","source":"## 9. Defining Loss Function and Optimizer","metadata":{}},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(params=model.parameters(), lr = LEARNING_RATE)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.959453Z","iopub.execute_input":"2026-02-04T04:49:10.959738Z","iopub.status.idle":"2026-02-04T04:49:10.971173Z","shell.execute_reply.started":"2026-02-04T04:49:10.959710Z","shell.execute_reply":"2026-02-04T04:49:10.970633Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"optimizer","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.972060Z","iopub.execute_input":"2026-02-04T04:49:10.972284Z","iopub.status.idle":"2026-02-04T04:49:10.983363Z","shell.execute_reply.started":"2026-02-04T04:49:10.972266Z","shell.execute_reply":"2026-02-04T04:49:10.982728Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Adam (\nParameter Group 0\n    amsgrad: False\n    betas: (0.9, 0.999)\n    capturable: False\n    decoupled_weight_decay: False\n    differentiable: False\n    eps: 1e-08\n    foreach: None\n    fused: None\n    lr: 0.0003\n    maximize: False\n    weight_decay: 0\n)"},"metadata":{}}],"execution_count":23},{"cell_type":"markdown","source":"## 10. Training Loop Function","metadata":{}},{"cell_type":"code","source":"def train(model, loader, criterion, optimizer):\n\n    model.train()\n\n    total_loss, correct = 0, 0\n    for x, y in loader:\n        x, y = x.to(device), y.to(device)\n        optimizer.zero_grad()\n\n        # forward pass\n        out = model(x)\n\n        # loss per batch\n        loss = criterion(out, y)\n\n        # performing backpropagation/ gradient Calculation\n        loss.backward()\n\n        # Update parameters\n        optimizer.step()\n        \n        total_loss += loss.item() * x.size(0)\n        correct += (out.argmax(1) == y).sum().item()\n\n    # return average batch loss, average correct prediction in each batch\n    return total_loss / len(loader.dataset), correct / len(loader.dataset)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.985247Z","iopub.execute_input":"2026-02-04T04:49:10.985428Z","iopub.status.idle":"2026-02-04T04:49:10.995268Z","shell.execute_reply.started":"2026-02-04T04:49:10.985411Z","shell.execute_reply":"2026-02-04T04:49:10.994712Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"def evaluate(model, loader):\n    model.eval()\n\n    total_loss, correct = 0, 0\n\n    with torch.inference_mode():\n        for x, y in loader:\n            x, y = x.to(device), y.to(device)\n            out = model(x)\n            correct += (out.argmax(1) == y).sum().item()\n\n    return correct / len(loader.dataset)\n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:10.996009Z","iopub.execute_input":"2026-02-04T04:49:10.996219Z","iopub.status.idle":"2026-02-04T04:49:11.006379Z","shell.execute_reply.started":"2026-02-04T04:49:10.996201Z","shell.execute_reply":"2026-02-04T04:49:11.005679Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from tqdm.auto import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:11.007248Z","iopub.execute_input":"2026-02-04T04:49:11.007643Z","iopub.status.idle":"2026-02-04T04:49:11.143328Z","shell.execute_reply.started":"2026-02-04T04:49:11.007611Z","shell.execute_reply":"2026-02-04T04:49:11.142577Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## 11. Training Model","metadata":{}},{"cell_type":"code","source":"train_accuracies, test_accuracies = [], []\ntrain_losses = []\n\nfor epoch in tqdm(range(EPOCHS)):\n    train_loss, train_acc = train(\n        model = model,\n        loader = train_loader,\n        optimizer = optimizer,\n        criterion = criterion\n    )\n\n    test_acc = evaluate(\n        model = model,\n        loader = test_loader\n    )\n\n    train_accuracies.append(train_acc)\n    test_accuracies.append(test_acc)\n\n    train_losses.append(train_loss)\n\n    print(f\"Epoch: {epoch+1}/{EPOCHS}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_acc:.4f}, Test Accuracy: {test_acc:.4f}\")\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-04T04:49:11.144313Z","iopub.execute_input":"2026-02-04T04:49:11.144596Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/30 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6721315cbdf64ed98ce4bb0992b6ac76"}},"metadata":{}},{"name":"stdout","text":"Epoch: 1/30, Train Loss: 2.1138, Train Accuracy: 0.2110, Test Accuracy: 0.2584\nEpoch: 2/30, Train Loss: 1.9521, Train Accuracy: 0.2734, Test Accuracy: 0.3038\nEpoch: 3/30, Train Loss: 1.8505, Train Accuracy: 0.2956, Test Accuracy: 0.3236\nEpoch: 4/30, Train Loss: 1.7792, Train Accuracy: 0.3264, Test Accuracy: 0.3256\nEpoch: 5/30, Train Loss: 1.7034, Train Accuracy: 0.3564, Test Accuracy: 0.4022\nEpoch: 6/30, Train Loss: 1.6715, Train Accuracy: 0.3648, Test Accuracy: 0.3851\nEpoch: 7/30, Train Loss: 1.6514, Train Accuracy: 0.3794, Test Accuracy: 0.4204\nEpoch: 8/30, Train Loss: 1.5990, Train Accuracy: 0.4032, Test Accuracy: 0.3994\nEpoch: 9/30, Train Loss: 1.5785, Train Accuracy: 0.4062, Test Accuracy: 0.4070\nEpoch: 10/30, Train Loss: 1.5688, Train Accuracy: 0.4048, Test Accuracy: 0.4285\nEpoch: 11/30, Train Loss: 1.5285, Train Accuracy: 0.4254, Test Accuracy: 0.4409\nEpoch: 12/30, Train Loss: 1.5177, Train Accuracy: 0.4320, Test Accuracy: 0.4421\nEpoch: 13/30, Train Loss: 1.4893, Train Accuracy: 0.4444, Test Accuracy: 0.4273\nEpoch: 14/30, Train Loss: 1.4907, Train Accuracy: 0.4406, Test Accuracy: 0.4281\nEpoch: 15/30, Train Loss: 1.4578, Train Accuracy: 0.4490, Test Accuracy: 0.4389\nEpoch: 16/30, Train Loss: 1.4502, Train Accuracy: 0.4544, Test Accuracy: 0.4561\nEpoch: 17/30, Train Loss: 1.4386, Train Accuracy: 0.4552, Test Accuracy: 0.4581\nEpoch: 18/30, Train Loss: 1.4179, Train Accuracy: 0.4622, Test Accuracy: 0.4759\nEpoch: 19/30, Train Loss: 1.4101, Train Accuracy: 0.4676, Test Accuracy: 0.4809\nEpoch: 20/30, Train Loss: 1.3971, Train Accuracy: 0.4846, Test Accuracy: 0.4813\nEpoch: 21/30, Train Loss: 1.3715, Train Accuracy: 0.4874, Test Accuracy: 0.4908\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"plt.plot(train_accuracies, label=\"Train Accuracy\")\nplt.plot(test_accuracies, label=\"Test Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.legend()\nplt.title(\"Training and Test Accuracy\")\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 12. Getting Predictions","metadata":{}},{"cell_type":"code","source":"def predict(model, dataset, classes, grid_size = 3):\n    model.eval()\n    fig, axes = plt.subplots(grid_size, grid_size, figsize=(9,9))\n    for i in range(grid_size):\n        for j in range(grid_size):\n            idx = random.randint(0, len(dataset)-1)\n            img, label = dataset[idx]\n            true_label = label\n            input_tensor = img.unsqueeze(dim=0).to(device)\n            with torch.inference_mode():\n                output = model(input_tensor)\n                _, predicted = torch.max(output, 1)\n            img = img / 2 + 0.5\n            npimg = img.cpu().numpy()\n            axes[i, j].imshow(np.transpose(npimg, (1, 2, 0)))\n            truth = classes[true_label] == classes[predicted.item()]\n            if truth:\n                color = \"g\"\n            else:\n                color = \"r\"\n\n            axes[i, j].set_title(f\"Truth: {classes[true_label]}\\n Predicted: {classes[predicted.item()]}\", fontsize=10, c=color)\n\n            axes[i, j].axis(\"off\")\n\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"predict(\n    model = model,\n    dataset = test_data, \n    classes = train_data.classes,\n    grid_size = 4\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# save model weights\ntorch.save(model.state_dict(), \"vit_stl10.pth\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}